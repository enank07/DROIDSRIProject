{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsY2luvW961nUA/p+vmsys",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enank07/DROIDSRIProject/blob/main/XGBoostenankhan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hey, this is the XGBoost project workspace! All directories have been removed for privacy reasons, so please feel free to put your own in. Have fun! - Enan"
      ],
      "metadata": {
        "id": "XhHT1YlMk9QL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl8O8xHsA17w"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "    cellxgene-census[tiledbsoma] \\\n",
        "    scanpy anndata tiledbsoma \\\n",
        "    xgboost scikit-learn\n",
        "\n",
        "!pip install -q scikit-misc\n",
        "!pip install --user scikit-misc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scanpy as sc\n",
        "import anndata\n",
        "import cellxgene_census as cxc\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"anndata\")"
      ],
      "metadata": {
        "id": "uRUUi6kpN3vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounted drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_dir = Path(\"\")\n",
        "project_dir.mkdir(parents=True, exist_ok=True)\n",
        "adata_path = project_dir / \"covid_3kHVG.h5ad\""
      ],
      "metadata": {
        "id": "CS3cZOKrOW-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check data\n",
        "import cellxgene_census as cxc\n",
        "import pandas as pd\n",
        "censusgarbage= \"2025-01-30\"\n",
        "idcollection = \"ddfad306-714d-4cc0-9985-d9072820c530\"\n",
        "with cxc.open_soma(census_version=censusgarbage) as census:\n",
        "    #data pull\n",
        "    ds = (\n",
        "        census[\"census_info\"][\"datasets\"]\n",
        "        .read()\n",
        "        .concat()\n",
        "        .to_pandas() #pandas switch\n",
        "        .set_index(\"soma_joinid\")\n",
        "    )\n",
        "my_ds= ds.query(\"collection_id == @idcollection\")\n",
        "print(my_ds[[\"dataset_id\", \"dataset_title\", \"dataset_total_cell_count\"]])"
      ],
      "metadata": {
        "id": "Sv3IxKGuS6uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data maker with AnnData\n",
        "import cellxgene_census as cxc\n",
        "import scanpy as sc\n",
        "\n",
        "censusgarbage = \"2025-01-30\"                            #good id\n",
        "DATASET_ID     = \"c7775e88-49bf-4ba2-a03b-93f00447c958\"\n",
        "\n",
        "with cxc.open_soma(census_version=censusgarbage) as census:\n",
        "    adata = cxc.get_anndata(\n",
        "        census=census,\n",
        "        organism=\"Homo sapiens\",\n",
        "        obs_value_filter=(\n",
        "            f'dataset_id == \"{DATASET_ID}\" '\n",
        "            'and is_primary_data == True'            #all canonical cell\n",
        "        )\n",
        "    )\n",
        "\n",
        "print(adata)\n",
        "print(adata.obs.head())"
      ],
      "metadata": {
        "id": "u3Iux9PJS_KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preparation\n",
        "import scanpy as sc\n",
        "\n",
        "#normalize data via log1p to remove bias between cells (sum library bias crpa)\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "sc.pp.log1p(adata)\n",
        "adata.layers[\"log1p\"] = adata.X.copy()   #keep copy\n",
        "\n",
        "#VARY IT TO NUANCE (hyperparameters: 3000)\n",
        "sc.pp.highly_variable_genes(\n",
        "    adata, n_top_genes=3_000, layer=\"log1p\", flavor=\"seurat_v3\", subset=True\n",
        ")\n",
        "print(adata)      #check data"
      ],
      "metadata": {
        "id": "1Oc9UeCgTIM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data splitting and label preparation\n",
        "adata.obs[\"cell_type_code\"] = adata.obs[\"cell_type\"].astype(\"category\").cat.codes\n",
        "y_cell = adata.obs[\"cell_type_code\"].values\n",
        "n_cell_classes = len(adata.obs[\"cell_type\"].cat.categories)\n",
        "\n",
        "#binary labels\n",
        "adata.obs[\"disease_code\"] = (adata.obs[\"disease\"] != \"normal\").astype(int)\n",
        "y_disease = adata.obs[\"disease_code\"].values\n",
        "\n",
        "# Get the feature matrix (gene expression) as a NumPy array\n",
        "X = adata.X.toarray()\n",
        "\n",
        "#train + val + group shuffle split\n",
        "groups = adata.obs[\"donor_id\"].values\n",
        "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
        "train_idx, val_idx = next(gss.split(X, groups=groups))\n",
        "\n",
        "#create training and validation sets for features and both targets\n",
        "X_train, X_val = X[train_idx], X[val_idx]\n",
        "y_cell_train, y_cell_val = y_cell[train_idx], y_cell[val_idx]\n",
        "y_disease_train, y_disease_val = y_disease[train_idx], y_disease[val_idx]\n",
        "\n",
        "print(f\"Data split into training ({len(train_idx)} cells) and validation ({len(val_idx)} cells).\")"
      ],
      "metadata": {
        "id": "4h3WnIEeO1ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import xgboost as xgb\n",
        "from pathlib import Path\n",
        "\n",
        "#setup+path\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#define path in drive\n",
        "project_dir = Path(\"\")\n",
        "project_dir.mkdir(parents=True, exist_ok=True) #ensure directory exists\n",
        "cell_model_path = project_dir / \"xgb_cell_classifier_final.ubj\"\n",
        "print(f\"Cell-type model will be saved to: {cell_model_path}\")\n",
        "\n",
        "#cell type classifer\n",
        "print(\"\\n--- Training Cell-Type Classifier ---\")\n",
        "\n",
        "#define classifier\n",
        "xgb_cell_classifier = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=n_cell_classes,\n",
        "    n_estimators=50,\n",
        "    early_stopping_rounds=50,\n",
        "    tree_method='hist',\n",
        "    eval_metric=['mlogloss', 'merror'],\n",
        "    device=device,\n",
        "    random_state= #choose\n",
        ")\n",
        "\n",
        "#train and print\n",
        "xgb_cell_classifier.fit(\n",
        "    X_train,\n",
        "    y_cell_train,\n",
        "    eval_set=[(X_val, y_cell_val)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nCell-type classifier training complete.\")\n",
        "print(f\"Saving model to {cell_model_path}...\")\n",
        "xgb_cell_classifier.save_model(cell_model_path)\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "id": "G3feRP97PLtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xg boost disease classifier\n",
        "import torch\n",
        "import xgboost as xgb\n",
        "from pathlib import Path\n",
        "\n",
        "#path\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#defined\n",
        "project_dir = Path(\"\")\n",
        "project_dir.mkdir(parents=True, exist_ok=True) #directory exists\n",
        "disease_model_path = project_dir / \"xgb_disease_classifier_final.ubj\"\n",
        "print(f\"Disease model will be saved to: {disease_model_path}\")\n",
        "\n",
        "\n",
        "#classifier\n",
        "print(\"\\n--- Training Disease Classifier ---\")\n",
        "\n",
        "#xgboost\n",
        "xgb_disease_classifier = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    n_estimators=50,\n",
        "    early_stopping_rounds=50,\n",
        "    tree_method='hist',\n",
        "    eval_metric=['logloss', 'auc', 'error'],\n",
        "    device=device,\n",
        "    random_state= #choose\n",
        ")\n",
        "\n",
        "#train, print output every 1 loop\n",
        "xgb_disease_classifier.fit(\n",
        "    X_train,\n",
        "    y_disease_train,\n",
        "    eval_set=[(X_val, y_disease_val)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nDisease classifier training complete.\")\n",
        "print(f\"Saving model to {disease_model_path}...\")\n",
        "xgb_disease_classifier.save_model(disease_model_path)\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "id": "iAP14wPPPYYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DO THE CONFUSION MATRIXES as well..."
      ],
      "metadata": {
        "id": "B_c3GIlitWE4"
      }
    }
  ]
}